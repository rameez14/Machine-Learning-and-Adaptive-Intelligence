{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective Functions: A Simple Example with Matrix Factorisation.\n",
    "\n",
    "### 6th October 2015 Neil D. Lawrence\n",
    "\n",
    "### Modified by Mauricio A Álvarez, 1st October 2018\n",
    "\n",
    "In last week's class we saw how we could load in a data set to pandas and use it for some simple data processing. We computed various probabilities on the data and I encouraged you to think about what sort of probabilities you need for prediction. This week we are going to take a slightly different tack. \n",
    "\n",
    "Broadly speaking there are two dominating approaches to machine learning problems. We started to consider the first approach last week: constructing models based on defining the relationship between variables using probabilities. This week we will consider the second approach: which involves defining an *objective function* and optimizing it. \n",
    "\n",
    "What do we mean by an objective function? An objective function could be an *error function*, a *cost function* or a *benefit* function. In evolutionary computing they are called *fitness* functions. But the idea is always the same. We write down a mathematical equation which is then optimized to do the learning. The equation should be a function of the *data* and our model *parameters*. We have a choice when optimizing, either minimize or maximize. To avoid confusion, in the optimization field, we always choose to minimize the function. If we have a function that we would like to maximize, we simply choose to minimize the negative of that function. \n",
    "\n",
    "So for this lab session, we are going to ignore probabilities, but don't worry, they will return! \n",
    "\n",
    "This week we are going to try and build a simple movie recommender system using an objective function. To do this, the first thing I'd like you to do is to install some software we've written for sharing information across google documents.\n",
    "\n",
    "## Open Data Science Software\n",
    "\n",
    "In Sheffield we have written a suite of software tools for 'Open Data Science'. Open data science is an approach to sharing code, models and data that should make it easier for companies, health professionals and scientists to gain access to data science techniques. For some background on open data science you can read [this blog post](http://inverseprobability.com/2014/07/01/open-data-science/). The first thing we will do this week is to download that suite of software. \n",
    "\n",
    "The software can be installed using\n",
    "\n",
    "```python\n",
    "pip install pods\n",
    "```\n",
    "\n",
    "from the command prompt where you can access your python installation.\n",
    "\n",
    "\n",
    "## Download the MovieLens 100k Data\n",
    "\n",
    "We are going to download the [MovieLens 100k](http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html) Data. This is a public dataset that contains 100,000 ratings and 3,600 tag applications applied to 9,000 movies by 600 users. When you use a data set that someone has prepared you should always reference the data source to acknowledge the work that's been placed in. This particular dataset was collected by the [Grouplens Research group](https://grouplens.org/),  at the University of Minnesota. For example, if you were to use this dataset for writing a paper, the authors ask you that you acknowledge their work by citing the following paper:\n",
    "\n",
    "F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5 (4):1-19 [https://doi.org/10.1145/2827872](https://doi.org/10.1145/2827872)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading  http://files.grouplens.org/datasets/movielens/ml-latest-small.zip -> .\\ml-latest-small.zip\n",
      "[==============================]   0.933/0.933MB                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n"
     ]
    }
   ],
   "source": [
    "import pods\n",
    "import zipfile\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pods.util.download_url(\"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\")\n",
    "zip_console = zipfile.ZipFile('ml-latest-small.zip', 'r')\n",
    "for name in zip_console.namelist():\n",
    "           zip_console.extract(name, './')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Question 1\n",
    "\n",
    "Data ethics. If you find data available on the internet, can you simply use it without consequence? If you are given data by a fellow researcher can you publish that data on line? \n",
    "\n",
    "*5 marks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 Answer\n",
    "\n",
    "The defintion of the term data ethics is also known as big data ethics which refers the legal concepts If you are given data by a fellow researcher can you publish that data on lineof right to data in particulary personal and private data. In this era of the internet data has been regarded as important as this contains huge amount of data and intellectual property. Data ethicsi growing at a rapid pace and it refers to appiled ethics for value judgements, this may include data protection laws such as the new general data protection regulation, it should encompass good practice in computing and information assurance. \n",
    "\n",
    "If you find someone else data available on the interent you can always seek permission to use the data or you can always buy the rights from them or seek their permission to buy it from them. Furthermore, the concept of licensing you will have to agree to the terms and conditions to use the data. This will allow you to use the resources for a short period of time. However, if you use someone else data that is available online without their permission this is reffered to as 'IP infringement' this could lead to a fine, prison or even both. There are two types of using data the first on being plagiarism which is not referencing the work where you got it from and each insitution has it owns rules for this, mainly failing the individual for that submitted work. The second one being copyright infringement this is where you copy other work without permission. The consequences for this is that its illegal and you could be asked to come to court where the court can impose a 6 month imprisoment and or a fine up £50,000. There are seven frameworks of data ethics principles.\n",
    "\n",
    "1 . It needs to be clear and benefical for the public\n",
    "2 . Making sure that you are aware of the legislation and the codes of practice that are associated with it\n",
    "3 . Using data that is corresponding to the need of the users\n",
    "4 . Being fully aware regarding the limitations of the data\n",
    "5 . Ensuring that strong practices are comfortable for the users\n",
    "6 . Making work clear and held to liable \n",
    "7 . Enclose data use in good hands and in a ethical and efficient manner\n",
    "\n",
    "If you are given data by your fellow reseracher you cannot just simply post it online. If you have the full permission from your fellow reseracher than you can post it online otherwise no because this could be considered unethical. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender Systems\n",
    "\n",
    "A recommender system aims to make suggestions for items (films, books, other commercial products) given what it knows about users' tastes. The recommendation engine needs to represent the *taste* of all the users and the *characteristics* of each object. \n",
    "\n",
    "A common way for organizing objects is to place related objects spatially close together. For example in a library we try and put books that are on related topics near to each other on the shelves. One system for doing this is known as [Dewey Decimal Classification](http://en.wikipedia.org/wiki/Dewey_Decimal_Classification). In the Dewey Decimal Classification system (which dates from 1876) each subject is given a number (in fact it's a decimal number). For example, the field of Natural Sciences and Mathematics is given numbers which start with 500. Subjects based on Computer Science are given numbers which start 004 and works on the 'mathematical principles' of Computer science are given the series 004.0151 (which we might store as 4.0151 on a Computer). Whilst it's a classification system, the books in the library are typically laid out in the same order as the numbers, so we might expect that neighbouring numbers represent books that are related in subject. That seems to be exactly what we want when also representing films. Could we somehow represent each film's subject according to a number? In a similar way we could then imagine representing users with a list of numbers that represent things that each user is interested in.\n",
    "\n",
    "Actually a one dimensional representation of a subject can be very awkward. To see this, let's have a look at the Dewey Decimal Classification numbers for the 900s, which is listed as 'History and Geography'. We will focus on subjects in the 940s which can be found in this list from [Wikipedia](https://en.wikipedia.org/wiki/List_of_Dewey_Decimal_classes#Class_900_%E2%80%93_History_&_geography). Whilst the ordering for places is somewhat sensible, it is also rather arbitrary. In the 940s we have Europe listed from 940-949, Asia listed from 950-959 and Africa listed from 960-969. Whilst it's true that Asia borders Europe, Africa is also very close, and the history of the Roman Empire spreads into [Carthage](http://en.wikipedia.org/wiki/Carthage) and later on Egypt. This image from Wikipedia shows a map of the Cathaginian Empire which fell after fighting with Rome. \n",
    "\n",
    "\n",
    "<a title=\"By Javierfv1212 [Public domain], from Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Carthaginianempire.PNG\"><img width=\"512\" alt=\"Carthaginianempire\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9b/Carthaginianempire.PNG/512px-Carthaginianempire.PNG\"></a>\n",
    "\n",
    "We now need to make a decision about whether Roman Histories are European or African, ideally we'd like them to be somewhere between the two, but we can't place them there in the Dewey Decimal system because between Europe and Africa is Asia, which has less to do with the Roman Empire than either Europe or Africa. Of course the fact that we've used a map provides a clue as to what to do next. Libraries are actually laid out on floors, so what if we were to use the spatial lay out to organise the sujbects of the books in two dimensions. Books on Geography could be laid out according to where in the world they are referring to. \n",
    "\n",
    "Such complexities are very hard to encapsulate in one number, but inspired by the map examples we can start considering how we might lay out films in two dimensions. Similarly, we can consider laying out a map of people's interests. If the two maps correspond to one another, the map of people could reflect where they might want to live in 'subject space'. We can think of representing people's tastes as where they might best like to sit in the library to access easily the books they are most interested in.\n",
    "\n",
    "\n",
    "## Inner Products for Representing Similarity\n",
    "\n",
    "Ideas like the above are good for gaining intuitions about what we might want, but the one of the skills of data science is representing those ideas mathematically. Mathematical abstraction of a problem is one of the key ways in which we've been able to progress as a society. Understanding planetary motions, as well as those of the smallest molecule (to quote Laplace's [Philosophical Essay on Probabilities](http://books.google.co.uk/books?id=1YQPAAAAQAAJ&printsec=frontcover&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false)) needed to be done mathematically. The right mathematical model in machine learning can be slightly more elusive, because constructing it is a two stage process. \n",
    "\n",
    "1. We have to determine the right intuition for the system we want to represent. Notions such as 'subject' and 'interest' are not mathematically well defined, and even when we create a new interpretation of what they might mean, each interpretation may have its own weaknesses. \n",
    "\n",
    "2. Once we have our interpretation we can attempt to mathematically formalize it. In our library interpretation, that's what we need to do next. \n",
    "\n",
    "### The Library on an Infinite Plane\n",
    "\n",
    "Let's imagine a library which stores all the items  we are interested in, not just books, but films and shopping items too. Such a library is likely to be very large, so we'll create it on an infinite two dimensional plane. This means we can use all the real numbers to represent the location of each item on the plane. For a two dimensional plane, we need to store the locations in a vector of numbers: we can decide that the $j$th item's location in the library is given by \n",
    "$$\n",
    "\\mathbf{v}_j = \\begin{bmatrix} v_{j,1} \\\\ v_{j,2}\\end{bmatrix},\n",
    "$$\n",
    "where $v_{j,1}$ represents the $j$th item's location in the East-West direction (or the $x$-axis) and $v_{j,2}$ represents the $j$th item's location in the North-South direction (or the $y$-axis). Now we need to specify the location where each user sits so that all the items that interest them are nearby: we can also represent the $i$th user's location with a vector \n",
    "$$\n",
    "\\mathbf{u}_i = \\begin{bmatrix} u_{i,1} \\\\ u_{i,2}\\end{bmatrix}.\n",
    "$$\n",
    "Finally, we need some way of recording a given user's affinity for a given item. This affinity might be the rating that the user gives the film. We can use $y_{i,j}$ to represent user $i$'s affinity for item $j$. \n",
    "\n",
    "For our film example we might imagine wanting to order films in a few ways. We could imagine organising films in the North-South direction as to how romantic they are. We could place the more romantic films further North and the less romantic films further South. For the East-West direction we could imagine ordering them according to how historic they are: we can imagine placing science fiction films to the East and historical drama to the West. In this case, fans of historical romances would be based in the North-West location, whilst fans of Science Fiction Action films might be located in the South-East (if we assume that 'Action' is the opposite of 'Romance', which is not necessarily the case). How do we lay out all these films? Have we got the right axes? In machine learning the answer is to 'let the data speak'. Use the data to try and obtain such a lay out. To do this we first need to obtain the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the Data\n",
    "\n",
    "As mentioned before, the MovieLens dataset that we'll use has 100,000 ratings to 9,000 movies by 600 users. For now, we will only work with a subset of the dataset. In particular, we will randomly chose a particular number of users and extract the movies and ratings that the users gave to those movies. Read the code below and understand what it is doing.\n",
    "\n",
    "**Before you run the code**, notice that `YourStudentID` in the first line is a variable that will specify the seed for the random number generator that will select a particular set of `nUsersInExample` users. Change the number that has been assigned by default to `YourStudentID` to the last three digits of your UCard number. All of you will have a different subset of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "YourStudentID = 579  # Include here the last three digits of your UCard number\n",
    "nUsersInExample = 10 # The maximum number of Users we're going to analyse at one time\n",
    "\n",
    "ratings = pd.read_csv(\"./ml-latest-small/ratings.csv\") \n",
    "\"\"\"\n",
    "ratings is a DataFrame with four columns: userId, movieId, rating and tags. We\n",
    "first want to identify how many unique users there are. We can use the unique \n",
    "method in pandas\n",
    "\"\"\"\n",
    "indexes_unique_users = ratings['userId'].unique()\n",
    "n_users = indexes_unique_users.shape[0]\n",
    "\"\"\" \n",
    "We randomly select 'nUsers' users with their ratings. We first fix the seed\n",
    "of the random generator to make sure that we always get the same 'nUsers'\n",
    "\"\"\"\n",
    "np.random.seed(YourStudentID)\n",
    "indexes_users = np.random.permutation(n_users)\n",
    "my_batch_users = indexes_users[0:nUsersInExample]\n",
    "\"\"\"\n",
    "We will use now the list of 'my_batch_users' to create a matrix Y. \n",
    "\"\"\"\n",
    "# We need to make a list of the movies that these users have watched\n",
    "list_movies_each_user = [[] for _ in range(nUsersInExample)]\n",
    "list_ratings_each_user = [[] for _ in range(nUsersInExample)]\n",
    "# Movies\n",
    "list_movies = ratings['movieId'][ratings['userId'] == my_batch_users[0]].values\n",
    "list_movies_each_user[0] = list_movies                    \n",
    "# Ratings                      \n",
    "list_ratings = ratings['rating'][ratings['userId'] == my_batch_users[0]].values\n",
    "list_ratings_each_user[0] = list_ratings\n",
    "# Users\n",
    "n_each_user = list_movies.shape[0]\n",
    "list_users = my_batch_users[0]*np.ones((1, n_each_user))\n",
    "\n",
    "for i in range(1, nUsersInExample):\n",
    "    # Movies\n",
    "    local_list_per_user_movies = ratings['movieId'][ratings['userId'] == my_batch_users[i]].values\n",
    "    list_movies_each_user[i] = local_list_per_user_movies\n",
    "    list_movies = np.append(list_movies,local_list_per_user_movies)\n",
    "    # Ratings                                 \n",
    "    local_list_per_user_ratings = ratings['rating'][ratings['userId'] == my_batch_users[i]].values\n",
    "    list_ratings_each_user[i] = local_list_per_user_ratings\n",
    "    list_ratings = np.append(list_ratings, local_list_per_user_ratings)  \n",
    "    # Users                                   \n",
    "    n_each_user = local_list_per_user_movies.shape[0]                                                                               \n",
    "    local_rep_user =  my_batch_users[i]*np.ones((1, n_each_user))    \n",
    "    list_users = np.append(list_users, local_rep_user)\n",
    "\n",
    "# Let us first see how many unique movies have been rated\n",
    "indexes_unique_movies = np.unique(list_movies)\n",
    "n_movies = indexes_unique_movies.shape[0]\n",
    "# As it is expected no all users have rated all movies. We will build a matrix Y \n",
    "# with NaN inputs and fill according to the data for each user \n",
    "temp = np.empty((n_movies,nUsersInExample,))\n",
    "temp[:] = np.nan\n",
    "Y_with_NaNs = pd.DataFrame(temp)\n",
    "for i in range(nUsersInExample):\n",
    " local_movies = list_movies_each_user[i]\n",
    " ixs = np.in1d(indexes_unique_movies, local_movies)\n",
    " Y_with_NaNs.loc[ixs, i] = list_ratings_each_user[i]\n",
    "\n",
    "Y_with_NaNs.index = indexes_unique_movies.tolist()\n",
    "Y_with_NaNs.columns = my_batch_users.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Question 2\n",
    "\n",
    "Have a look at the matrix `Y_with_NaNs`. The movies data is now in a data frame which contains one column for each user rating the movie. There are some entries that contain 'NaN'. What does the 'NaN' mean in this context?\n",
    "\n",
    "*5 marks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer Question 2\n",
    "\n",
    "The meaning on 'NaN' in this context is that it means not a number however positive and negitive infinity is assigned to 0. As stated before 'NaN' is not a number you cannot do calculate/compute it. Moreover, it is a data type value representing not defined value mainly for floating point calculations, if 'NaN' is to be calculated it will return 'NaN'. Moreover, 'NaN' is considered as that some data is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will convert our data structure into a form that is appropriate for processing. We will convert the `Y_with_NaNs` dataframe into a new dataframe which contains the user, the movie, and the rating using the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7489894907033143\n",
      "      users  movies  ratingsorig   ratings\n",
      "0     137.0       1          4.0  0.251011\n",
      "1     137.0     110          4.0  0.251011\n",
      "2     137.0     111          5.0  1.251011\n",
      "3     137.0     150          3.5 -0.248989\n",
      "4     137.0     246          5.0  1.251011\n",
      "5     137.0     260          4.0  0.251011\n",
      "6     137.0     272          4.0  0.251011\n",
      "7     137.0     296          3.0 -0.748989\n",
      "8     137.0     318          3.5 -0.248989\n",
      "9     137.0     356          3.5 -0.248989\n",
      "10    137.0     480          3.5 -0.248989\n",
      "11    137.0     527          3.5 -0.248989\n",
      "12    137.0     541          5.0  1.251011\n",
      "13    137.0     588          4.0  0.251011\n",
      "14    137.0     589          3.5 -0.248989\n",
      "15    137.0     590          3.5 -0.248989\n",
      "16    137.0     593          4.0  0.251011\n",
      "17    137.0     608          4.5  0.751011\n",
      "18    137.0     724          3.0 -0.748989\n",
      "19    137.0     750          5.0  1.251011\n",
      "20    137.0     778          2.0 -1.748989\n",
      "21    137.0     780          3.0 -0.748989\n",
      "22    137.0     858          5.0  1.251011\n",
      "23    137.0     903          4.0  0.251011\n",
      "24    137.0     904          4.0  0.251011\n",
      "25    137.0     908          4.5  0.751011\n",
      "26    137.0     910          4.0  0.251011\n",
      "27    137.0     912          5.0  1.251011\n",
      "28    137.0     913          4.5  0.751011\n",
      "29    137.0     919          5.0  1.251011\n",
      "...     ...     ...          ...       ...\n",
      "1207  416.0    2571          1.0 -2.748989\n",
      "1208  416.0    2716          2.0 -1.748989\n",
      "1209  416.0    2762          2.5 -1.248989\n",
      "1210  416.0    2858          3.5 -0.248989\n",
      "1211  416.0    2959          4.0  0.251011\n",
      "1212  416.0    2997          5.0  1.251011\n",
      "1213  416.0    3624          2.0 -1.748989\n",
      "1214  416.0    3677          4.0  0.251011\n",
      "1215  416.0    4306          0.5 -3.248989\n",
      "1216  416.0    4361          1.0 -2.748989\n",
      "1217  416.0    4848          4.0  0.251011\n",
      "1218  416.0    4886          0.5 -3.248989\n",
      "1219  416.0    4967          4.0  0.251011\n",
      "1220  416.0    4973          4.0  0.251011\n",
      "1221  416.0    4979          5.0  1.251011\n",
      "1222  416.0    4995          2.5 -1.248989\n",
      "1223  416.0    5303          4.0  0.251011\n",
      "1224  416.0    5445          1.0 -2.748989\n",
      "1225  416.0    5617          4.5  0.751011\n",
      "1226  416.0    5902          4.0  0.251011\n",
      "1227  416.0    5951          5.0  1.251011\n",
      "1228  416.0    5952          2.5 -1.248989\n",
      "1229  416.0    6365          0.5 -3.248989\n",
      "1230  416.0    6539          2.0 -1.748989\n",
      "1231  416.0    6874          3.5 -0.248989\n",
      "1232  416.0    7323          4.5  0.751011\n",
      "1233  416.0    8360          0.5 -3.248989\n",
      "1234  416.0    8959          3.5 -0.248989\n",
      "1235  416.0   26810          5.0  1.251011\n",
      "1236  416.0   46976          5.0  1.251011\n",
      "\n",
      "[1237 rows x 4 columns]\n",
      "        137  352  367  406  210  473  4    345  370  416\n",
      "1       4.0  NaN  5.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "11      NaN  NaN  NaN  NaN  NaN  NaN  NaN  2.5  NaN  NaN\n",
      "21      NaN  NaN  NaN  NaN  NaN  NaN  3.0  NaN  NaN  NaN\n",
      "32      NaN  NaN  NaN  NaN  NaN  NaN  2.0  3.5  NaN  NaN\n",
      "34      NaN  NaN  3.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "39      NaN  NaN  4.0  NaN  NaN  NaN  NaN  NaN  3.5  NaN\n",
      "45      NaN  NaN  NaN  NaN  NaN  NaN  3.0  NaN  NaN  NaN\n",
      "47      NaN  5.0  NaN  NaN  NaN  NaN  2.0  NaN  3.5  NaN\n",
      "50      NaN  5.0  NaN  NaN  NaN  NaN  NaN  NaN  4.5  NaN\n",
      "52      NaN  NaN  NaN  NaN  NaN  NaN  3.0  NaN  NaN  NaN\n",
      "58      NaN  NaN  NaN  NaN  NaN  NaN  3.0  NaN  NaN  NaN\n",
      "60      NaN  NaN  NaN  NaN  NaN  2.0  NaN  NaN  NaN  NaN\n",
      "106     NaN  NaN  NaN  NaN  NaN  NaN  4.0  NaN  NaN  NaN\n",
      "110     4.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "111     5.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "112     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  3.5  NaN\n",
      "125     NaN  NaN  NaN  NaN  NaN  NaN  5.0  NaN  NaN  NaN\n",
      "126     NaN  NaN  NaN  NaN  NaN  NaN  1.0  NaN  NaN  NaN\n",
      "135     NaN  NaN  NaN  4.0  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "150     3.5  NaN  4.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "153     NaN  NaN  NaN  NaN  3.5  NaN  NaN  NaN  NaN  NaN\n",
      "162     NaN  NaN  NaN  NaN  NaN  NaN  5.0  NaN  NaN  NaN\n",
      "170     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  2.5\n",
      "171     NaN  NaN  NaN  NaN  NaN  NaN  3.0  NaN  NaN  NaN\n",
      "176     NaN  NaN  NaN  NaN  NaN  NaN  5.0  NaN  NaN  NaN\n",
      "190     NaN  NaN  NaN  NaN  NaN  NaN  2.0  NaN  NaN  NaN\n",
      "215     NaN  NaN  NaN  NaN  NaN  NaN  5.0  NaN  NaN  NaN\n",
      "222     NaN  NaN  NaN  NaN  NaN  NaN  1.0  NaN  NaN  NaN\n",
      "223     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  4.5  NaN\n",
      "232     NaN  NaN  NaN  NaN  NaN  NaN  5.0  NaN  NaN  NaN\n",
      "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
      "130444  NaN  NaN  NaN  NaN  4.0  NaN  NaN  NaN  NaN  NaN\n",
      "130490  NaN  2.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "130634  NaN  1.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "134130  NaN  5.0  NaN  NaN  4.5  NaN  NaN  NaN  NaN  NaN\n",
      "135133  NaN  4.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "135143  NaN  4.0  NaN  NaN  4.5  NaN  NaN  NaN  NaN  NaN\n",
      "135569  NaN  4.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "135887  NaN  NaN  NaN  NaN  4.0  NaN  NaN  NaN  NaN  NaN\n",
      "139385  NaN  5.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "140359  NaN  NaN  NaN  NaN  4.5  NaN  NaN  NaN  NaN  NaN\n",
      "146662  NaN  NaN  NaN  NaN  5.0  NaN  NaN  NaN  NaN  NaN\n",
      "147372  NaN  NaN  NaN  NaN  4.5  NaN  NaN  NaN  NaN  NaN\n",
      "147374  NaN  NaN  NaN  NaN  4.5  NaN  NaN  NaN  NaN  NaN\n",
      "147376  NaN  NaN  NaN  NaN  4.5  NaN  NaN  NaN  NaN  NaN\n",
      "147378  NaN  NaN  NaN  NaN  4.5  NaN  NaN  NaN  NaN  NaN\n",
      "147380  NaN  NaN  NaN  NaN  4.5  NaN  NaN  NaN  NaN  NaN\n",
      "147382  NaN  NaN  NaN  NaN  4.5  NaN  NaN  NaN  NaN  NaN\n",
      "147384  NaN  NaN  NaN  NaN  4.5  NaN  NaN  NaN  NaN  NaN\n",
      "150596  NaN  NaN  NaN  NaN  4.5  NaN  NaN  NaN  NaN  NaN\n",
      "152077  NaN  4.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "159779  NaN  NaN  NaN  NaN  4.0  NaN  NaN  NaN  NaN  NaN\n",
      "164179  NaN  3.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "166203  NaN  NaN  NaN  NaN  4.0  NaN  NaN  NaN  NaN  NaN\n",
      "166528  NaN  4.5  NaN  NaN  4.5  NaN  NaN  NaN  NaN  NaN\n",
      "177765  NaN  NaN  NaN  NaN  5.0  NaN  NaN  NaN  NaN  NaN\n",
      "179511  NaN  NaN  NaN  NaN  4.0  NaN  NaN  NaN  NaN  NaN\n",
      "179819  NaN  NaN  NaN  NaN  4.5  NaN  NaN  NaN  NaN  NaN\n",
      "180031  NaN  NaN  NaN  NaN  4.0  NaN  NaN  NaN  NaN  NaN\n",
      "184053  NaN  NaN  NaN  NaN  2.0  NaN  NaN  NaN  NaN  NaN\n",
      "189547  NaN  NaN  NaN  NaN  1.0  NaN  NaN  NaN  NaN  NaN\n",
      "\n",
      "[938 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "p_list_ratings = np.concatenate(list_ratings_each_user).ravel()\n",
    "p_list_ratings_original = p_list_ratings.tolist()\n",
    "mean_ratings_train = np.mean(p_list_ratings)\n",
    "p_list_ratings =  p_list_ratings - mean_ratings_train # remove the mean\n",
    "p_list_movies = np.concatenate(list_movies_each_user).ravel().tolist()\n",
    "p_list_users = list_users.tolist()\n",
    "Y = pd.DataFrame({'users': p_list_users, 'movies': p_list_movies, 'ratingsorig': p_list_ratings_original,'ratings':p_list_ratings.tolist()})\n",
    "print(mean_ratings_train)\n",
    "print(Y)\n",
    "print(Y_with_NaNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Question 3\n",
    "\n",
    "The dataframes `Y_with_NaNs` and `Y` contain the same information but organised in a different way. Explain what is the difference. We have also included two columns for ratings in dataframe `Y`, `ratingsorig` and `ratings`. Explain\n",
    "the difference. \n",
    "\n",
    "*10 marks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3 Answer\n",
    "\n",
    "Both dataframes print out the same information but in unique and different ways. The table regarding Y has a readble format easy to read in comparision to Y_with NaNs. The dataframe Y_with_NaNs has more columns compared to Y but less rows. Y gets rid off the 'NaNs' values which makes it easier to read. The dataframe regarding Y_with_NaNs contains NaN values which is diificult to understand and read and hard to read what is what in terms of data in the table. If we look at mean_ratings_train and if we were to print this out we get the number 3.7489894907033143 as this prints out the mean. if we were to subtract this number by ratingsortig we get the sum of the ratings. So in short if ratingsortig subtract the mean number it will show the result and calculate the ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Similarity\n",
    "\n",
    "We now need a measure for determining the similarity between the item and the user: how close the user is sitting to the item in the rooom if you like. We are going to use the inner product between the vector representing the item and the vector representing the user. \n",
    "\n",
    "An inner product (or [dot product](http://en.wikipedia.org/wiki/Dot_product)) between two vectors $\\mathbf{a}$ and $\\mathbf{b}$ is written as $\\mathbf{a}\\cdot\\mathbf{b}$. Or in vector notation we sometimes write it as $\\mathbf{a}^\\top\\mathbf{b}$. An inner product is simply the sume of the products of each element of the vector,\n",
    "$$\n",
    "\\mathbf{a}^\\top\\mathbf{b} = \\sum_{i} a_i b_i\n",
    "$$\n",
    "The inner product can be seen as a measure of similarity. The inner product gives us the cosine of the angle between the two vectors multiplied by their length. The smaller the angle between two vectors the larger the inner product. \n",
    "$$\n",
    "\\mathbf{a}^\\top\\mathbf{b} = |\\mathbf{a}||\\mathbf{b}| \\cos(\\theta)\n",
    "$$\n",
    "where $\\theta$ is the angle between two vectors and $|\\mathbf{a}|$ and $|\\mathbf{b}|$ are the respective lengths of the two vectors.\n",
    "\n",
    "Since we want each user to be sitting near each item, then we want the inner product to be large for any two items which are rated highly by that user. We can do this by trying to force the inner product $\\mathbf{u}_i^\\top\\mathbf{v}_j$ to be similar to the rating given by the user, $y_{i,j}$. To ensure this we will use a least squares objective function for all user ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Function\n",
    "\n",
    "The error function (or objective function, or cost function) we will choose is known as 'sum of squares', we will aim to minimize the sum of squared squared error between the inner product of $\\mathbf{u}_i$ and $\\mathbf{v}_i$ and the observed score for the user/item pairing, given by $y_{i, j}$. \n",
    "\n",
    "The total objective function can be written as\n",
    "$$\n",
    "E(\\mathbf{U}, \\mathbf{V}) = \\sum_{i,j} s_{i,j} (y_{i,j} - \\mathbf{u}_i^\\top \\mathbf{v}_j)^2\n",
    "$$\n",
    "where $s_{i,j}$ is an *indicator* variable that is 1 if user $i$ has rated item $j$ and is zero otherwise. Here $\\mathbf{U}$ is the matrix made up of all the vectors $\\mathbf{u}$,\n",
    "$$\n",
    "\\mathbf{U} = \\begin{bmatrix} \\mathbf{u}_1 \\dots \\mathbf{u}_n\\end{bmatrix}^\\top\n",
    "$$\n",
    "where we note that $i$th *row* of $\\mathbf{U}$ contains the vector associated with the $i$th user and $n$ is the total number of users. This form of matrix is known as a *design matrix*. Similarly, we define the matrix\n",
    "$$\n",
    "\\mathbf{V} = \\begin{bmatrix} \\mathbf{v}_1 \\dots \\mathbf{v}_m\\end{bmatrix}^\\top\n",
    "$$\n",
    "where again the $j$th row of $\\mathbf{V}$ contains the vector associated with the $j$th item and $m$ is the total number of items in the data set.\n",
    "\n",
    "## Objective Optimization\n",
    "\n",
    "The idea is to mimimize this objective. A standard, simple, technique for minimizing an objective is *gradient descent* or *steepest descent*. In gradient descent we simply choose to update each parameter in the model by subtracting a multiple of the objective function's gradient with respect to the parameters. So for a parameter $u_{i,j}$ from the matrix $\\mathbf{U}$ we would have an update as follows:\n",
    "$$\n",
    "u_{k,\\ell} \\leftarrow u_{k,\\ell} - \\eta \\frac{\\text{d} E(\\mathbf{U}, \\mathbf{V})}{\\text{d}u_{k,\\ell}} \n",
    "$$\n",
    "where $\\eta$ (which is pronounced *eta* in English) is a Greek letter representing the *learning rate*.  \n",
    "\n",
    "We can compute the gradient of the objective function with respect to $u_{k,\\ell}$ as\n",
    "$$\n",
    "\\frac{\\text{d}E(\\mathbf{U}, \\mathbf{V})}{\\text{d}u_{k,\\ell}} = -2 \\sum_j s_{k,j}v_{j,\\ell}(y_{k, j} - \\mathbf{u}_k^\\top\\mathbf{v}_{j}). \n",
    "$$\n",
    "Similarly each parameter $v_{i,j}$ needs to be updated according to its gradient. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Question 4\n",
    "\n",
    "What is the gradient of the objective function with respect to $v_{k, \\ell}$? Write your answer in the box below, and explain which differentiation techniques you used to get there. You will be expected to justify your answer in class by oral questioning. \n",
    "\n",
    "*15 marks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4 Answer\n",
    "\n",
    "In order to find the gradient of the objective function with regards to vk,ℓ first we need to derive this. In order to do this we need to use the power rule. Power rule is that it informs us how to differentiate expressions regarding the $$x^n$$ which x represents the raised power. In simple terms one can take the power and then multiply this aganist the expression then eventually one can lessen the power by 1. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\text{d}E(\\mathbf{U}, \\mathbf{V})}{\\text{d}v_{k,\\ell}} = -2 \\sum_j s_{k,j}u_{k,\\ell}(y_{k, j} - \\mathbf{u}_k^\\top\\mathbf{v}_{j}). \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steepest Descent Algorithm\n",
    "\n",
    "In the steepest descent algorithm we aim to minimize the objective function by subtacting the gradient of the objective function from the parameters. \n",
    "\n",
    "### Initialisation\n",
    "\n",
    "To start with though, we need initial values for the matrix $\\mathbf{U}$ and the matrix $\\mathbf{V}$. Let's create them as `pandas` data frames and initialise them randomly with small values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 2 # the dimension of our map of the 'library'\n",
    "learn_rate = 0.01\n",
    "U = pd.DataFrame(np.random.normal(size=(nUsersInExample, q))*0.001, index=my_batch_users)\n",
    "V = pd.DataFrame(np.random.normal(size=(n_movies, q))*0.001, index=indexes_unique_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the initial values set, we can start the optimization. First we define a function for the gradient of the objective and the objective function itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_gradient(Y, U, V):\n",
    "    gU = pd.DataFrame(np.zeros((U.shape)), index=U.index)\n",
    "    gV = pd.DataFrame(np.zeros((V.shape)), index=V.index)\n",
    "    obj = 0.\n",
    "    nrows = Y.shape[0]\n",
    "    for i in range(nrows):\n",
    "        row = Y.iloc[i]\n",
    "        user = row['users']\n",
    "        film = row['movies']\n",
    "        rating = row['ratings']\n",
    "        prediction = np.dot(U.loc[user], V.loc[film]) # vTu\n",
    "        diff = prediction - rating # vTu - y\n",
    "        obj += diff*diff\n",
    "        gU.loc[user] += 2*diff*V.loc[film]\n",
    "        gV.loc[film] += 2*diff*U.loc[user]\n",
    "    return obj, gU, gV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write our simple optimisation route. This allows us to observe the objective function as the optimization proceeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 Objective function:  1331.8113754154504\n",
      "Iteration 1 Objective function:  1331.8110946858255\n",
      "Iteration 2 Objective function:  1331.8107940788939\n",
      "Iteration 3 Objective function:  1331.8103521768692\n",
      "Iteration 4 Objective function:  1331.8096028660266\n"
     ]
    }
   ],
   "source": [
    "iterations = 5\n",
    "for i in range(iterations):\n",
    "    obj, gU, gV = objective_gradient(Y, U, V)\n",
    "    print(\"Iteration\", i, \"Objective function: \", obj)\n",
    "    U -= learn_rate*gU\n",
    "    V -= learn_rate*gV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Question 5\n",
    "\n",
    "What happens as you increase the number of iterations? What happens if you increase the learning rate?\n",
    "\n",
    "*10 marks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5 Answer\n",
    "\n",
    "If you change the number of iterations the objective function iteration number goes smaller as this happens it changes to inf then eventually nan value. If you increase the number of iteration it will reach the value of inf value which eventually reaches the nan value. The lower the learn_rate the higer the iteration number each time round. Furthermore, more objective function value will occur. The more iterations that are added more the more operation will occur which will result in a smaller number and maybe the it will result to a NaN value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 Objective function:  1331.811132393721\n",
      "Iteration 1 Objective function:  1331.8088587482998\n",
      "Iteration 2 Objective function:  1331.7722872851903\n",
      "Iteration 3 Objective function:  1331.1075578100654\n"
     ]
    }
   ],
   "source": [
    "# Question 5 Code Answer\n",
    "\n",
    "learn_rate=0.1\n",
    "q = 2 # the dimension of our map of the 'library'\n",
    "U = pd.DataFrame(np.random.normal(size=(nUsersInExample, q))*0.001, index=my_batch_users)\n",
    "V = pd.DataFrame(np.random.normal(size=(n_movies, q))*0.001, index=indexes_unique_movies)\n",
    "\n",
    "iterations = 4\n",
    "for i in range(iterations):\n",
    "    obj, gU, gV = objective_gradient(Y, U, V)\n",
    "    print(\"Iteration\", i, \"Objective function: \", obj)\n",
    "    U -= learn_rate*gU\n",
    "    V -= learn_rate*gV    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "\n",
    "Predictions can be made from the model of the appropriate rating for a given user, $i$, for a given film, $j$, by simply taking the inner product between their vectors $\\mathbf{u}_i$ and $\\mathbf{v}_j$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Question 6\n",
    "\n",
    "Create a function that provides the prediction of the ratings for the users in the dataset. Is the quality of the predictions affected by the number of iterations or the learning rate? The function should receive `Y`, `U` and `V` and return the predictions and the absolute error between the predictions and the actual rating given by the users. The predictions and the absolute error should be added as additional columns to the dataframe `Y`.\n",
    "\n",
    "*15 marks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      users  movies  ratingsorig   ratings    Prediction  Absolute Error\n",
      "0     137.0       1          4.0  0.251011  3.041447e-07        0.251010\n",
      "1     137.0     110          4.0  0.251011 -7.931434e-07        0.251011\n",
      "2     137.0     111          5.0  1.251011  1.127194e-06        1.251009\n",
      "3     137.0     150          3.5 -0.248989 -8.215652e-07        0.248989\n",
      "4     137.0     246          5.0  1.251011  7.751233e-07        1.251010\n",
      "5     137.0     260          4.0  0.251011  2.533026e-08        0.251010\n",
      "6     137.0     272          4.0  0.251011 -3.725217e-07        0.251011\n",
      "7     137.0     296          3.0 -0.748989 -1.330162e-06        0.748988\n",
      "8     137.0     318          3.5 -0.248989 -7.801898e-07        0.248989\n",
      "9     137.0     356          3.5 -0.248989  7.519501e-07        0.248990\n",
      "10    137.0     480          3.5 -0.248989  4.174636e-07        0.248990\n",
      "11    137.0     527          3.5 -0.248989 -8.859279e-07        0.248989\n",
      "12    137.0     541          5.0  1.251011  2.957758e-07        1.251010\n",
      "13    137.0     588          4.0  0.251011 -5.672844e-07        0.251011\n",
      "14    137.0     589          3.5 -0.248989 -1.380401e-06        0.248988\n",
      "15    137.0     590          3.5 -0.248989 -9.652851e-07        0.248989\n",
      "16    137.0     593          4.0  0.251011 -7.726771e-07        0.251011\n",
      "17    137.0     608          4.5  0.751011  2.419230e-06        0.751008\n",
      "18    137.0     724          3.0 -0.748989  4.399801e-07        0.748990\n",
      "19    137.0     750          5.0  1.251011  8.627982e-08        1.251010\n",
      "20    137.0     778          2.0 -1.748989  6.989868e-07        1.748990\n",
      "21    137.0     780          3.0 -0.748989 -1.691329e-07        0.748989\n",
      "22    137.0     858          5.0  1.251011 -2.151683e-07        1.251011\n",
      "23    137.0     903          4.0  0.251011 -9.841334e-07        0.251011\n",
      "24    137.0     904          4.0  0.251011  7.294535e-08        0.251010\n",
      "25    137.0     908          4.5  0.751011 -2.973730e-07        0.751011\n",
      "26    137.0     910          4.0  0.251011  6.297251e-07        0.251010\n",
      "27    137.0     912          5.0  1.251011  1.165291e-06        1.251009\n",
      "28    137.0     913          4.5  0.751011 -9.776064e-07        0.751011\n",
      "29    137.0     919          5.0  1.251011  8.783764e-08        1.251010\n",
      "...     ...     ...          ...       ...           ...             ...\n",
      "1207  416.0    2571          1.0 -2.748989 -9.710842e-07        2.748989\n",
      "1208  416.0    2716          2.0 -1.748989 -2.532116e-07        1.748989\n",
      "1209  416.0    2762          2.5 -1.248989 -7.269163e-07        1.248989\n",
      "1210  416.0    2858          3.5 -0.248989 -7.890018e-07        0.248989\n",
      "1211  416.0    2959          4.0  0.251011 -1.316649e-06        0.251012\n",
      "1212  416.0    2997          5.0  1.251011  3.682656e-07        1.251010\n",
      "1213  416.0    3624          2.0 -1.748989  8.763959e-07        1.748990\n",
      "1214  416.0    3677          4.0  0.251011 -4.883175e-07        0.251011\n",
      "1215  416.0    4306          0.5 -3.248989 -5.841190e-07        3.248989\n",
      "1216  416.0    4361          1.0 -2.748989 -3.813657e-07        2.748989\n",
      "1217  416.0    4848          4.0  0.251011 -7.441667e-07        0.251011\n",
      "1218  416.0    4886          0.5 -3.248989  4.975764e-08        3.248990\n",
      "1219  416.0    4967          4.0  0.251011  5.747792e-07        0.251010\n",
      "1220  416.0    4973          4.0  0.251011  7.118494e-07        0.251010\n",
      "1221  416.0    4979          5.0  1.251011  1.208421e-07        1.251010\n",
      "1222  416.0    4995          2.5 -1.248989  2.339879e-07        1.248990\n",
      "1223  416.0    5303          4.0  0.251011  1.407488e-06        0.251009\n",
      "1224  416.0    5445          1.0 -2.748989  8.958502e-08        2.748990\n",
      "1225  416.0    5617          4.5  0.751011  3.200471e-07        0.751010\n",
      "1226  416.0    5902          4.0  0.251011  4.688385e-07        0.251010\n",
      "1227  416.0    5951          5.0  1.251011  5.565969e-08        1.251010\n",
      "1228  416.0    5952          2.5 -1.248989 -5.746992e-07        1.248989\n",
      "1229  416.0    6365          0.5 -3.248989  3.849615e-07        3.248990\n",
      "1230  416.0    6539          2.0 -1.748989 -4.066405e-07        1.748989\n",
      "1231  416.0    6874          3.5 -0.248989 -1.402141e-06        0.248988\n",
      "1232  416.0    7323          4.5  0.751011  5.832240e-07        0.751010\n",
      "1233  416.0    8360          0.5 -3.248989 -1.697039e-07        3.248989\n",
      "1234  416.0    8959          3.5 -0.248989 -2.680835e-07        0.248989\n",
      "1235  416.0   26810          5.0  1.251011  6.022501e-07        1.251010\n",
      "1236  416.0   46976          5.0  1.251011 -4.217148e-07        1.251011\n",
      "\n",
      "[1237 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Question 6 Code Answer\n",
    "nrows = Y.shape[0]\n",
    "a_list=[]\n",
    "b_list=[]\n",
    "for i in range(nrows):\n",
    "        row = Y.iloc[i]\n",
    "        user = row['users']\n",
    "        film = row['movies']\n",
    "        rating = row['ratings']\n",
    "        prediction = np.dot(U.loc[user], V.loc[film]) \n",
    "        diff=abs(prediction - rating)\n",
    "        a_list.append(prediction)\n",
    "        b_list.append(diff)\n",
    "Y['Prediction']=a_list\n",
    "Y['Absolute Error']=b_list\n",
    "print(Y)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent or Robbins Monroe Algorithm\n",
    "\n",
    "Stochastic gradient descent involves updating separating each gradient update according to each separate observation, rather than summing over them all. It is an approximate optimization method, but it has proven convergence under certain conditions and can be much faster in practice. It is used widely by internet companies for doing machine learning in practice. For example, Facebook's ad ranking algorithm uses stochastic gradient descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Question 7\n",
    "\n",
    "Create a stochastic gradient descent version of the algorithm. Monitor the objective function after every 1000 updates to ensure that it is decreasing. When you have finished, plot the movie map and the user map in two dimensions (you can use the columns of the matrices $\\mathbf{U}$ for the user map and the columns of $\\mathbf{V}$ for the movie map). Provide three observations about these maps.\n",
    "\n",
    "*25 marks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 Objective function 1331.8112317800258\n",
      "Iteration 1000 Objective function 1331.810978992704\n",
      "Iteration 2000 Objective function 1331.8107626478115\n",
      "Iteration 3000 Objective function 1331.8104146795401\n",
      "Iteration 4000 Objective function 1331.8100339733373\n",
      "Iteration 5000 Objective function 1331.8091610399479\n",
      "Iteration 6000 Objective function 1331.8078429537452\n",
      "Iteration 7000 Objective function 1331.80603034883\n",
      "Iteration 8000 Objective function 1331.80303664946\n",
      "Iteration 9000 Objective function 1331.7976916605496\n",
      "Iteration 10000 Objective function 1331.7905295523963\n",
      "Iteration 11000 Objective function 1331.7753568711917\n",
      "Iteration 12000 Objective function 1331.7525874585642\n",
      "Iteration 13000 Objective function 1331.7102989615555\n",
      "Iteration 14000 Objective function 1331.6426050141158\n",
      "Iteration 15000 Objective function 1331.5158555364842\n",
      "Iteration 16000 Objective function 1331.3068883732592\n",
      "Iteration 17000 Objective function 1330.8889977966069\n",
      "Iteration 18000 Objective function 1330.1795122542314\n",
      "Iteration 19000 Objective function 1329.0688231484044\n",
      "Iteration 20000 Objective function 1326.8537830251078\n",
      "Iteration 21000 Objective function 1322.8071045576291\n",
      "Iteration 22000 Objective function 1316.3987394458302\n",
      "Iteration 23000 Objective function 1304.1876780276189\n",
      "Iteration 24000 Objective function 1281.3090912894806\n",
      "Iteration 25000 Objective function 1240.8648315144198\n",
      "Iteration 26000 Objective function 1185.847885666764\n",
      "Iteration 27000 Objective function 1120.1654294959758\n",
      "Iteration 28000 Objective function 1056.3449079100924\n",
      "Iteration 29000 Objective function 991.7073848947621\n",
      "Iteration 30000 Objective function 938.7798068969036\n",
      "Iteration 31000 Objective function 901.1760650326396\n",
      "Iteration 32000 Objective function 863.2144854904452\n",
      "Iteration 33000 Objective function 828.3738573572601\n",
      "Iteration 34000 Objective function 795.1114523224801\n",
      "Iteration 35000 Objective function 758.0299328674129\n",
      "Iteration 36000 Objective function 723.5614579745952\n",
      "Iteration 37000 Objective function 682.3433339081936\n",
      "Iteration 38000 Objective function 642.2804655565045\n",
      "Iteration 39000 Objective function 597.3104254988624\n",
      "Iteration 40000 Objective function 550.9090645646128\n",
      "Iteration 41000 Objective function 512.9005513794385\n",
      "Iteration 42000 Objective function 486.09460613024385\n",
      "Iteration 43000 Objective function 454.8879304026436\n",
      "Iteration 44000 Objective function 433.09351534826493\n",
      "Iteration 45000 Objective function 411.20316706574545\n",
      "Iteration 46000 Objective function 386.794397741783\n",
      "Iteration 47000 Objective function 363.89088768838013\n",
      "Iteration 48000 Objective function 346.30642945261\n",
      "Iteration 49000 Objective function 334.9655930982272\n",
      "Iteration 50000 Objective function 318.29893837507615\n",
      "Iteration 51000 Objective function 306.13283272442686\n",
      "Iteration 52000 Objective function 287.8579693325918\n",
      "Iteration 53000 Objective function 279.44778212838173\n",
      "Iteration 54000 Objective function 267.5069644447352\n",
      "Iteration 55000 Objective function 261.41984075859693\n",
      "Iteration 56000 Objective function 250.7718279243368\n",
      "Iteration 57000 Objective function 243.83524136569395\n",
      "Iteration 58000 Objective function 233.97765828371425\n",
      "Iteration 59000 Objective function 230.0519465006608\n",
      "Iteration 60000 Objective function 218.17928967841317\n",
      "Iteration 61000 Objective function 212.12859527678134\n",
      "Iteration 62000 Objective function 206.67918334189864\n",
      "Iteration 63000 Objective function 200.9387724566408\n",
      "Iteration 64000 Objective function 202.0458145389645\n",
      "Iteration 65000 Objective function 190.24889550073866\n",
      "Iteration 66000 Objective function 180.06837686923797\n",
      "Iteration 67000 Objective function 177.08130123827044\n",
      "Iteration 68000 Objective function 166.70574484785794\n",
      "Iteration 69000 Objective function 162.84250287937832\n",
      "Iteration 70000 Objective function 158.54939945100148\n",
      "Iteration 71000 Objective function 153.64548548260404\n",
      "Iteration 72000 Objective function 153.63538590250462\n",
      "Iteration 73000 Objective function 150.6652458612394\n",
      "Iteration 74000 Objective function 148.84645291117408\n",
      "Iteration 75000 Objective function 145.65046186057185\n",
      "Iteration 76000 Objective function 144.9419183112996\n",
      "Iteration 77000 Objective function 142.72108837736283\n",
      "Iteration 78000 Objective function 142.64715172879593\n",
      "Iteration 79000 Objective function 137.4991252934092\n",
      "Iteration 80000 Objective function 140.28884993977553\n",
      "Iteration 81000 Objective function 140.69103064361093\n",
      "Iteration 82000 Objective function 136.37788518911591\n",
      "Iteration 83000 Objective function 141.1703879410744\n",
      "Iteration 84000 Objective function 131.72415322168104\n",
      "Iteration 85000 Objective function 132.71811784526741\n",
      "Iteration 86000 Objective function 136.21994746034053\n",
      "Iteration 87000 Objective function 132.42162924687125\n",
      "Iteration 88000 Objective function 133.41483295700866\n",
      "Iteration 89000 Objective function 134.20047050996163\n",
      "Iteration 90000 Objective function 130.81399917849177\n",
      "Iteration 91000 Objective function 132.30377246515826\n",
      "Iteration 92000 Objective function 129.56933780752456\n",
      "Iteration 93000 Objective function 129.1671447990785\n",
      "Iteration 94000 Objective function 129.3113895259581\n",
      "Iteration 95000 Objective function 125.39285736911165\n",
      "Iteration 96000 Objective function 125.63842015041641\n",
      "Iteration 97000 Objective function 128.03067261513195\n",
      "Iteration 98000 Objective function 131.4750344426003\n",
      "Iteration 99000 Objective function 135.33864047907338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2f2b5b80b70>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question 7 Code Answer\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    " \n",
    "\n",
    "\n",
    "q = 2 # the dimension of our map of the 'library'\n",
    "learn_rate = 0.01\n",
    "U = pd.DataFrame(np.random.normal(size=(nUsersInExample, q))*0.001, index=my_batch_users)\n",
    "V = pd.DataFrame(np.random.normal(size=(n_movies, q))*0.001, index=indexes_unique_movies)\n",
    "\n",
    "def stochastic_gradient (Y, U, V):\n",
    "    gU = pd.DataFrame(np.zeros((U.shape)), index=U.index)\n",
    "    gV = pd.DataFrame(np.zeros((V.shape)), index=V.index)\n",
    "    n=np.random.randint(Y.shape[0])\n",
    "    nrows = Y.shape[0]\n",
    "    row = Y.iloc[n]\n",
    "    user = row['users']\n",
    "    film = row['movies']\n",
    "    rating = row['ratings']\n",
    "    prediction = np.dot(U.loc[user], V.loc[film]) # vTu\n",
    "    diff = prediction - rating # vTu - y\n",
    "   \n",
    "    gU.loc[user] += 2*diff*V.loc[film]\n",
    "    gV.loc[film] += 2*diff*U.loc[user]\n",
    "    return gU, gV\n",
    "\n",
    "iterations = 100000\n",
    "for i in range(iterations):\n",
    "    obj = 0\n",
    "    gU, gV = stochastic_gradient(Y, U, V)\n",
    "    U -= learn_rate*gU\n",
    "    V -= learn_rate*gV   \n",
    "    if i % 1000==0.0:\n",
    "        for n in range(nrows):\n",
    "            row = Y.iloc[n]\n",
    "            user = row['users']\n",
    "            film = row['movies']\n",
    "            rating = row['ratings']\n",
    "            prediction = np.dot(U.loc[user], V.loc[film]) # vTu\n",
    "            diff = prediction - rating # vTu - y\n",
    "            obj += diff*diff\n",
    "        print(\"Iteration\", i, \"Objective function\", obj)\n",
    "plt.title('Stochastic gradient')\n",
    "plt.plot(U[0], U[1], 'rx')\n",
    "plt.plot(V[0], V[1], 'bx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first observation that could be made is that if the users and the movie is close toghther the higher the chance the user will liked and reviewed the movie more. The second observation is that there is not enough users to get a good enough graph. The third observation is that we can compute more data faster using stochastic gradient descent.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is Our Map Enough? Are Our Data Enough?\n",
    "\n",
    "Is two dimensions really enough to capture the complexity of humans and their artforms? Perhaps we need even more dimensions to capture that complexity. Extending our books analogy further, consider how we should place books that have a historical timeframe as well as some geographical location. Do we really want books from the 2nd World War to sit alongside books from the Roman Empire? Books on the American invasion of Sicily in 1943 are perhaps less related to books about Carthage than those that study the Jewish Revolt from 66-70 (in the Roman Province of Judaea). So books that relate to subjects which are closer in time should be stored together. However, a student of rebellion against empire may also be interested in the relationship between the Jewish Revolt of 66-70 and the Indian Rebellion of 1857, nearly 1800 years later. Whilst the technologies are different, the psychology of the people is shared: a rebellious nation angainst their imperial masters, triggered by misrule with a religious and cultural background. To capture such complexities we would need further dimensions in our latent representation. But are further dimensions justified by the amount of data we have? Can we really understand the facets of a film that only has at most three or four ratings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going Further\n",
    "\n",
    "If you want to take this model further then you'll need more data. You can use again the MovieLens 100k data but increasing the number of users (for example, for the Steepest Descent Algorithm you can do this by modifying the variable `nUsersInExample` that was set as 10 before)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Question 8\n",
    "\n",
    "Use stochastic gradient descent to make a movie map for the MovieLens 100k data. Plot the map of the movies when you are finished.\n",
    "\n",
    "*15 marks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 Objective function 1409.048461608349\n",
      "Iteration 1000 Objective function 1409.0484623414363\n",
      "Iteration 2000 Objective function 1409.0484579731196\n",
      "Iteration 3000 Objective function 1409.048451905935\n",
      "Iteration 4000 Objective function 1409.0484525585343\n",
      "Iteration 5000 Objective function 1409.0484493414772\n",
      "Iteration 6000 Objective function 1409.0484467834904\n",
      "Iteration 7000 Objective function 1409.0484391005089\n",
      "Iteration 8000 Objective function 1409.0484377099983\n",
      "Iteration 9000 Objective function 1409.0484403333207\n",
      "Iteration 10000 Objective function 1409.048441674989\n",
      "Iteration 11000 Objective function 1409.0484451846512\n",
      "Iteration 12000 Objective function 1409.0484368825867\n",
      "Iteration 13000 Objective function 1409.0484347017054\n",
      "Iteration 14000 Objective function 1409.0484317485007\n",
      "Iteration 15000 Objective function 1409.0484233703478\n",
      "Iteration 16000 Objective function 1409.0484210987088\n",
      "Iteration 17000 Objective function 1409.0484089156814\n",
      "Iteration 18000 Objective function 1409.0484065528851\n",
      "Iteration 19000 Objective function 1409.048406196345\n",
      "Iteration 20000 Objective function 1409.048401520712\n",
      "Iteration 21000 Objective function 1409.0484055033155\n",
      "Iteration 22000 Objective function 1409.048407140342\n",
      "Iteration 23000 Objective function 1409.048407702919\n",
      "Iteration 24000 Objective function 1409.048390386154\n",
      "Iteration 25000 Objective function 1409.0483875291982\n",
      "Iteration 26000 Objective function 1409.0483817859058\n",
      "Iteration 27000 Objective function 1409.0483829247178\n",
      "Iteration 28000 Objective function 1409.048378988894\n",
      "Iteration 29000 Objective function 1409.048378454735\n",
      "Iteration 30000 Objective function 1409.0483728936106\n",
      "Iteration 31000 Objective function 1409.0483623525367\n",
      "Iteration 32000 Objective function 1409.048360955539\n",
      "Iteration 33000 Objective function 1409.048360445462\n",
      "Iteration 34000 Objective function 1409.048360018221\n",
      "Iteration 35000 Objective function 1409.0483501110562\n",
      "Iteration 36000 Objective function 1409.0483459984264\n",
      "Iteration 37000 Objective function 1409.0483402806237\n",
      "Iteration 38000 Objective function 1409.0483295944694\n",
      "Iteration 39000 Objective function 1409.0483299570903\n",
      "Iteration 40000 Objective function 1409.04832175012\n",
      "Iteration 41000 Objective function 1409.0483214242995\n",
      "Iteration 42000 Objective function 1409.0483142842463\n",
      "Iteration 43000 Objective function 1409.0483054587578\n",
      "Iteration 44000 Objective function 1409.0483027589864\n",
      "Iteration 45000 Objective function 1409.048301598333\n",
      "Iteration 46000 Objective function 1409.0482985991312\n",
      "Iteration 47000 Objective function 1409.048300722522\n",
      "Iteration 48000 Objective function 1409.0482916418157\n",
      "Iteration 49000 Objective function 1409.0482956392477\n",
      "Iteration 50000 Objective function 1409.048292606235\n",
      "Iteration 51000 Objective function 1409.0482944766627\n",
      "Iteration 52000 Objective function 1409.0482864884868\n",
      "Iteration 53000 Objective function 1409.048286001435\n",
      "Iteration 54000 Objective function 1409.0482778740725\n",
      "Iteration 55000 Objective function 1409.0482655928993\n",
      "Iteration 56000 Objective function 1409.0482447890845\n",
      "Iteration 57000 Objective function 1409.04821987807\n",
      "Iteration 58000 Objective function 1409.0482149841962\n",
      "Iteration 59000 Objective function 1409.0482134166657\n",
      "Iteration 60000 Objective function 1409.048203240579\n",
      "Iteration 61000 Objective function 1409.0482073447488\n",
      "Iteration 62000 Objective function 1409.0482062978565\n",
      "Iteration 63000 Objective function 1409.0482090064743\n",
      "Iteration 64000 Objective function 1409.0482032466914\n",
      "Iteration 65000 Objective function 1409.0481933233827\n",
      "Iteration 66000 Objective function 1409.048195094174\n",
      "Iteration 67000 Objective function 1409.0481847503584\n",
      "Iteration 68000 Objective function 1409.0481688285352\n",
      "Iteration 69000 Objective function 1409.0481618765123\n",
      "Iteration 70000 Objective function 1409.0481630191853\n",
      "Iteration 71000 Objective function 1409.04816056104\n",
      "Iteration 72000 Objective function 1409.0481606014794\n",
      "Iteration 73000 Objective function 1409.0481495381318\n",
      "Iteration 74000 Objective function 1409.0481445162743\n",
      "Iteration 75000 Objective function 1409.048144535131\n",
      "Iteration 76000 Objective function 1409.0481366392148\n",
      "Iteration 77000 Objective function 1409.0481288241965\n",
      "Iteration 78000 Objective function 1409.048119497811\n",
      "Iteration 79000 Objective function 1409.0481055560765\n",
      "Iteration 80000 Objective function 1409.0481037050952\n",
      "Iteration 81000 Objective function 1409.048088003757\n",
      "Iteration 82000 Objective function 1409.048082303731\n",
      "Iteration 83000 Objective function 1409.0480727806446\n",
      "Iteration 84000 Objective function 1409.0480655628644\n",
      "Iteration 85000 Objective function 1409.048054252291\n",
      "Iteration 86000 Objective function 1409.0480434285566\n",
      "Iteration 87000 Objective function 1409.048040504235\n",
      "Iteration 88000 Objective function 1409.048035138926\n",
      "Iteration 89000 Objective function 1409.0480418081304\n",
      "Iteration 90000 Objective function 1409.0480410543782\n",
      "Iteration 91000 Objective function 1409.0480370189025\n",
      "Iteration 92000 Objective function 1409.0480126969646\n",
      "Iteration 93000 Objective function 1409.048003976257\n",
      "Iteration 94000 Objective function 1409.0480013619754\n",
      "Iteration 95000 Objective function 1409.0479948720886\n",
      "Iteration 96000 Objective function 1409.0479855767207\n",
      "Iteration 97000 Objective function 1409.0479881755446\n",
      "Iteration 98000 Objective function 1409.0479691415344\n",
      "Iteration 99000 Objective function 1409.0479642250937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2f2bb02fb38>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code for question 8 here.\n",
    "\n",
    "YourStudentID = 579  # Include here the last three digits of your UCard number\n",
    "nUsersInExample = 610 # The maximum number of Users we're going to analyse at one time\n",
    "\n",
    "ratings = pd.read_csv(\"./ml-latest-small/ratings.csv\") \n",
    "\"\"\"\n",
    "ratings is a DataFrame with four columns: userId, movieId, rating and tags. We\n",
    "first want to identify how many unique users there are. We can use the unique \n",
    "method in pandas\n",
    "\"\"\"\n",
    "indexes_unique_users = ratings['userId'].unique()\n",
    "n_users = indexes_unique_users.shape[0]\n",
    "\"\"\" \n",
    "We randomly select 'nUsers' users with their ratings. We first fix the seed\n",
    "of the random generator to make sure that we always get the same 'nUsers'\n",
    "\"\"\"\n",
    "np.random.seed(YourStudentID)\n",
    "indexes_users = np.random.permutation(n_users)\n",
    "my_batch_users = indexes_users[0:nUsersInExample]\n",
    "\"\"\"\n",
    "We will use now the list of 'my_batch_users' to create a matrix Y. \n",
    "\"\"\"\n",
    "# We need to make a list of the movies that these users have watched\n",
    "list_movies_each_user = [[] for _ in range(nUsersInExample)]\n",
    "list_ratings_each_user = [[] for _ in range(nUsersInExample)]\n",
    "# Movies\n",
    "list_movies = ratings['movieId'][ratings['userId'] == my_batch_users[0]].values\n",
    "list_movies_each_user[0] = list_movies                    \n",
    "# Ratings                      \n",
    "list_ratings = ratings['rating'][ratings['userId'] == my_batch_users[0]].values\n",
    "list_ratings_each_user[0] = list_ratings\n",
    "# Users\n",
    "n_each_user = list_movies.shape[0]\n",
    "list_users = my_batch_users[0]*np.ones((1, n_each_user))\n",
    "\n",
    "for i in range(1, nUsersInExample):\n",
    "    # Movies\n",
    "    local_list_per_user_movies = ratings['movieId'][ratings['userId'] == my_batch_users[i]].values\n",
    "    list_movies_each_user[i] = local_list_per_user_movies\n",
    "    list_movies = np.append(list_movies,local_list_per_user_movies)\n",
    "    # Ratings                                 \n",
    "    local_list_per_user_ratings = ratings['rating'][ratings['userId'] == my_batch_users[i]].values\n",
    "    list_ratings_each_user[i] = local_list_per_user_ratings\n",
    "    list_ratings = np.append(list_ratings, local_list_per_user_ratings)  \n",
    "    # Users                                   \n",
    "    n_each_user = local_list_per_user_movies.shape[0]                                                                               \n",
    "    local_rep_user =  my_batch_users[i]*np.ones((1, n_each_user))    \n",
    "    list_users = np.append(list_users, local_rep_user)\n",
    "\n",
    "# Let us first see how many unique movies have been rated\n",
    "indexes_unique_movies = np.unique(list_movies)\n",
    "n_movies = indexes_unique_movies.shape[0]\n",
    "# As it is expected no all users have rated all movies. We will build a matrix Y \n",
    "# with NaN inputs and fill according to the data for each user \n",
    "temp = np.empty((n_movies,nUsersInExample,))\n",
    "temp[:] = np.nan\n",
    "Y_with_NaNs = pd.DataFrame(temp)\n",
    "for i in range(nUsersInExample):\n",
    "     local_movies = list_movies_each_user[i]\n",
    "     ixs = np.in1d(indexes_unique_movies, local_movies)\n",
    "     Y_with_NaNs.loc[ixs, i] = list_ratings_each_user[i]\n",
    "\n",
    "Y_with_NaNs.index = indexes_unique_movies.tolist()\n",
    "Y_with_NaNs.columns = my_batch_users.tolist()\n",
    "\n",
    "p_list_ratings = np.concatenate(list_ratings_each_user).ravel()\n",
    "p_list_ratings_original = p_list_ratings.tolist()\n",
    "mean_ratings_train = np.mean(p_list_ratings)\n",
    "p_list_ratings =  p_list_ratings - mean_ratings_train # remove the mean\n",
    "p_list_movies = np.concatenate(list_movies_each_user).ravel().tolist()\n",
    "p_list_users = list_users.tolist()\n",
    "Y = pd.DataFrame({'users': p_list_users, 'movies': p_list_movies, 'ratingsorig': p_list_ratings_original,'ratings':p_list_ratings.tolist()})\n",
    "\n",
    "q = 2 # the dimension of our map of the 'library'\n",
    "learn_rate = 0.01\n",
    "U = pd.DataFrame(np.random.normal(size=(nUsersInExample, q))*0.001, index=my_batch_users)\n",
    "V = pd.DataFrame(np.random.normal(size=(n_movies, q))*0.001, index=indexes_unique_movies)\n",
    "\n",
    "def stochastic_gradient (Y, U, V):\n",
    "    gU = pd.DataFrame(np.zeros((U.shape)), index=U.index)\n",
    "    gV = pd.DataFrame(np.zeros((V.shape)), index=V.index)\n",
    "    obj=0.\n",
    "    n=np.random.randint(Y.shape[0])\n",
    "    nrows = Y.shape[0]\n",
    "    row = Y.iloc[n]\n",
    "    user = row['users']\n",
    "    film = row['movies']\n",
    "    rating = row['ratings']\n",
    "    prediction = np.dot(U.loc[user], V.loc[film]) # vTu\n",
    "    diff = prediction - rating # vTu - y\n",
    "   \n",
    "    gU.loc[user] += 2*diff*V.loc[film]\n",
    "    gV.loc[film] += 2*diff*U.loc[user]\n",
    "    return gU, gV\n",
    "\n",
    "iterations = 100000\n",
    "for i in range(iterations):\n",
    "    obj = 0\n",
    "    gU, gV = stochastic_gradient(Y, U, V)\n",
    "    U -= learn_rate*gU\n",
    "    V -= learn_rate*gV   \n",
    "    if i % 1000==0.0:\n",
    "        for n in range(nrows):\n",
    "            row = Y.iloc[n]\n",
    "            user = row['users']\n",
    "            film = row['movies']\n",
    "            rating = row['ratings']\n",
    "            prediction = np.dot(U.loc[user], V.loc[film]) # vTu\n",
    "            diff = prediction - rating # vTu - y\n",
    "            obj += diff*diff\n",
    "        print(\"Iteration\", i, \"Objective function\", obj)\n",
    "plt.title('Stochastic gradient')\n",
    "plt.plot(V[0], V[1], 'rx')\n",
    "plt.plot(U[0], U[1], 'bo')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "\n",
    "Enago Academy. (2018). Should You Share Pre-Published Data? - Enago Academy. [online] Available at: https://www.enago.com/academy/should-you-share-pre-published-data/ [Accessed 5 Oct. 2018].\n",
    "\n",
    "GOV.UK. (2018). Data Ethics Framework. [online] Available at: https://www.gov.uk/government/publications/data-ethics-framework/data-ethics-framework [Accessed 4 Oct. 2018].\n",
    "\n",
    "GOV.UK. (2018). Using somebody else's intellectual property. [online] Available at: https://www.gov.uk/using-somebody-elses-intellectual-property/copyright [Accessed 5 Oct. 2018].\n",
    "\n",
    "Guyer, M., Rodriguez, H., Kaye, J., Heeney, C., Hawkins, N., de Vries, J., Boddington, P., Knoppers, B., Joly, Y., Sendorek, D., Caloian, C., Ellrott, K., Bare, J., Yamaguchi, T., Ewing, A., Houlahan, K., Norman, T., Margolin, A., Stuart, J., Boutros, P., Kaye, J., Terry, S., Juengst, E., Coy, S., Harris, J., Chalmers, D., Dove, E., Budin-Ljøsne, I., Adebamowo, C., Ogbe, E., Bezuidenhout, L., Morrison, M., Minion, J., Murtagh, M., Minari, J., Teare, H., Isasi, R., Kato, K., Rial-Sebbag, E., Marshall, P., Koenig, B., Cambon-Thomsen, A., Dyke, S., Linden, M., Lappalainen, I., Argila, J., Carey, K., Lloyd, D., Spalding, J., Cabili, M., Kerry, G., Foreman, J., Cutts, T., Shabani, M., Rodriguez, L., Haeussler, M., Walsh, B., Jiang, X., Wang, S., Perrett, D., Boughtwood, T., Matern, A., Brookes, A., Cupak, M., Fiume, M., Pandya, R., Tulchinsky, I., Scollen, S., Törnroos, J., Das, S., Evans, A., Malin, B., Beck, S., Brenner, S., Nyrönen, T., Blomberg, N., Firth, H., Hurles, M., Philippakis, A., Rätsch, G., Brudno, M., Boycott, K., Rehm, H., Baudis, M., Sherry, S., Kato, K., Knoppers, B., Baker, D. and Flicek, P. (2018). Prepublication data sharing. [online] Nature. Available at: https://www.nature.com/articles/461168a [Accessed 5 Oct. 2018].\n",
    "\n",
    "Johndcook.com. (2018). IEEE floating point arithmetic in Python: nan, inf, etc.. [online] Available at: https://www.johndcook.com/blog/2009/07/21/ieee-arithmetic-python/ [Accessed 7 Oct. 2018].\n",
    "\n",
    "nan?, W. (2018). What is inf and nan?. [online] Stack Overflow. Available at: https://stackoverflow.com/questions/17628613/what-is-inf-and-nan [Accessed 6 Oct. 2018].\n",
    "\n",
    "Oii.ox.ac.uk. (2018). What is data ethics? — Oxford Internet Institute. [online] Available at: https://www.oii.ox.ac.uk/news/releases/what-is-data-ethics/ [Accessed 4 Oct. 2018].\n",
    "\n",
    "Plagiarismchecker.com. (2018). Plagiarism vs. Copyright Infringement: Is Copying Illegal?. [online] Available at: http://www.plagiarismchecker.com/plagiarism-vs-copyright.php [Accessed 5 Oct. 2018].\n",
    "\n",
    "Service, U. (2018). Ten common copyright myths and misconceptions. [online] Copyrightservice.co.uk. Available at: https://www.copyrightservice.co.uk/copyright/copyright_myths [Accessed 5 Oct. 2018].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
